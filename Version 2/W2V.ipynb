{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZUrgpEXQCVe",
        "outputId": "77ec38e1-059d-46e9-e8b2-0756447fbce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Package abc is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import nltk,os, gensim,warnings,string,torch,logging\n",
        "\n",
        "nltk.download('abc')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "warnings.filterwarnings('ignore') \n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "import pandas as pd\n",
        "stop = stopwords.words('english')\n",
        "from textblob import Word\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import BertTokenizer, BertModel,AutoTokenizer, AutoModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4ycvTZgSo5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W2V for Embedding"
      ],
      "metadata": {
        "id": "b_MHT8W9SpQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Path = '/content/drive/MyDrive/Code'\n",
        "File = 'BT Forums Community.csv'\n",
        "data = pd.read_csv(os.path.join(Path,File))\n",
        "data['Text'] = data['Description'].apply(lambda x:' '.join([str(y).lower() for y in str(x).split()]))\n",
        "data['Text']= data['Text'].apply(lambda x: ' '.join(x for x in x.split() if x not in string.punctuation))\n",
        "data['Text']= data['Text'].str.replace('r[^\\w\\s]','')\n",
        "data['Text']= data['Text'].apply(lambda x: ' '.join(x for x in x.split() if  not x.isdigit()))\n",
        "data['Text']= data['Text'].apply(lambda x:' '.join(x for x in x.split() if not x in stop))\n",
        "data['Text']= data['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "Text = data['Text'].tolist()\n",
        "Text = [str(i).split() for i in Text[1:]]\n",
        "model= gensim.models.Word2Vec(Text)\n",
        "len(model.wv.get_vector('bt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_pWzbTsRG16",
        "outputId": "57730cdf-61c2-43e4-e0b7-66b02d8407f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.get_vector('bt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DzEPlc0TBX9",
        "outputId": "266a8612-617d-4262-ee4a-5a4b5adad9f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.25574863  0.30602738  0.9393921   0.77606446 -0.20954591  0.15743099\n",
            "  0.2818082   0.09141911 -0.47396025 -0.01382767 -0.05427597  0.03728221\n",
            "  0.16890208  0.3367922   0.3838529  -0.31099764 -0.03862688 -0.48292184\n",
            " -0.53515404 -0.18594557  0.31356514  0.07949005  0.1511097  -0.40665615\n",
            " -0.53483427 -0.38606182 -0.01922504 -0.2118337   0.79030734  0.16207998\n",
            "  0.07072143  0.07363675  0.5464291  -0.3960532  -0.04228822  0.3098498\n",
            " -0.5721123  -0.06114592 -0.04375873 -0.551937    0.0300998   0.7865605\n",
            " -0.34426668 -0.22822797  0.31043878  0.02343008 -0.24079883 -0.24289656\n",
            " -1.0322304  -0.19739975  0.77590406  0.03368454 -0.08126886  0.2916563\n",
            " -0.18913114  0.26203287 -0.23206322  0.19035068  0.40216005  0.21304157\n",
            "  0.25043488 -0.43542758  0.3718716  -0.04097221  0.11458331  0.2602234\n",
            "  0.7289224   0.19302517  0.34201375 -0.4326315  -0.44911745 -0.32971123\n",
            " -0.26535037 -0.14670442  0.13266952  0.23821832 -0.5727665   0.26210403\n",
            " -0.09788376 -0.8137084   0.13033885 -0.08805496  0.08301093  0.07036006\n",
            " -0.6867363   0.48817316 -0.0679718  -0.5163612   0.09072848 -0.20247051\n",
            "  0.09784432  0.13824677  1.3044858   0.2038414   0.07944296 -0.00773442\n",
            " -0.45431185  0.3904188   0.2712077  -0.15860263]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0QCn2jxTIOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W2V for encryption"
      ],
      "metadata": {
        "id": "yUYNPwq0TW2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['Text']\n",
        "VecModel = TfidfVectorizer()\n",
        "X_Vec = VecModel.fit_transform(X)\n",
        "X_Vec = pd.DataFrame.sparse.from_spmatrix(X_Vec)\n",
        "\n",
        "print(f'The new shape for X is {X_Vec.shape}')\n",
        "X_Vec.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "f5qf9cv-TILO",
        "outputId": "a3a2ff07-61c9-4db9-880c-e9d9e5b07af8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new shape for X is (1515, 8527)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     ...  8517  \\\n",
              "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "\n",
              "   8518  8519  8520  8521  8522  8523  8524  8525  8526  \n",
              "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "\n",
              "[5 rows x 8527 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a468b90-2c83-4b31-87f9-db4c94e02dd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>8517</th>\n",
              "      <th>8518</th>\n",
              "      <th>8519</th>\n",
              "      <th>8520</th>\n",
              "      <th>8521</th>\n",
              "      <th>8522</th>\n",
              "      <th>8523</th>\n",
              "      <th>8524</th>\n",
              "      <th>8525</th>\n",
              "      <th>8526</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8527 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a468b90-2c83-4b31-87f9-db4c94e02dd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a468b90-2c83-4b31-87f9-db4c94e02dd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a468b90-2c83-4b31-87f9-db4c94e02dd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(20) : \n",
        "  print(f'The Phrase is \\n                {data.loc[k,\"Text\"]}')\n",
        "  print(f'Embedding Values are : \\n                {[i for i in X_Vec.iloc[k,:].tolist() if i > 0.0]}')\n",
        "  \n",
        "  print('.......................................')\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSnsLbj1UBfa",
        "outputId": "e6d91bc8-1aa9-4be4-eeb8-1c2dd83f7e74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Phrase is \n",
            "                board topic\n",
            "Embedding Values are : \n",
            "                [0.661785769339262, 0.7496930008343689]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                p&g issue. previous bt community id ******@gmail.com (which active). left\n",
            "Embedding Values are : \n",
            "                [0.38880989537710386, 0.10914311090772147, 0.24314027411172714, 0.2623258609133205, 0.42432291339061323, 0.27729183133924207, 0.22673909079113172, 0.3561031054813354, 0.35021240708179757, 0.38880989537710386]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                received notification today allegedly bt asking confirm acceptance new term condition tomorrow (5 22) lose access information question genuine?\n",
            "Embedding Values are : \n",
            "                [0.245387912901906, 0.3480835034450046, 0.16056066904797886, 0.3480835034450046, 0.22455228692536475, 0.06589158667637136, 0.28484589107956326, 0.21498561334198163, 0.27466690904254726, 0.20605647099090288, 0.23870040559293626, 0.11846473404871004, 0.28484589107956326, 0.17813117344076504, 0.16208135302510362, 0.23870040559293626, 0.17055308111171205, 0.27466690904254726]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                hi commun hope everyone keeping safe well. can’t quite believe day christmas long see end 2021, year b\n",
            "Embedding Values are : \n",
            "                [0.28964727967115345, 0.2430797219054924, 0.1659701061444453, 0.31056011064562594, 0.3578199927315786, 0.1641278607594484, 0.20874216872767812, 0.2430797219054924, 0.11965662469278045, 0.25564511245177685, 0.3056442605748408, 0.2116902503837818, 0.247440971068767, 0.3011564410721209, 0.17632017635223812, 0.20140918003569833, 0.18414367108180646]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                i've email saying direct debit 'is longer active' nees set again. contains last number account, check genuine?\n",
            "Embedding Values are : \n",
            "                [0.16519407299710528, 0.2611585402164298, 0.20756173861465646, 0.2098177551538425, 0.33151577300069046, 0.3407689594614494, 0.2611585402164298, 0.14941054378757126, 0.3055903430693191, 0.22813991003130726, 0.1702231360155184, 0.22704842677243067, 0.3872725608094716, 0.17502508750693013, 0.2019942974751306, 0.1811968945494889, 0.14366723815769628]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                hello. correct place enquiry please feel free move it. received legit looking email stating direct debit longer active. contains actual bt link bt confirmed call sent them. also checked bt account bank account online dd still active. issue mail correctly quote last digit bt account, concerning. assuming scammer still issue forwarded phishing@bt com. anyone else this?\n",
            "Embedding Values are : \n",
            "                [0.2640227761437019, 0.27826584634904616, 0.16280408708788183, 0.08604030466462396, 0.07290085090651455, 0.15370645843990932, 0.17244796207910132, 0.19528052456360784, 0.09106500290784801, 0.11019003459963571, 0.08700605998159872, 0.18154559072707382, 0.14274338160385291, 0.17661593045290708, 0.11481243844966504, 0.14148556065792872, 0.19535743409209905, 0.18154559072707382, 0.15184101025182542, 0.13913292317452308, 0.10081790334662394, 0.07959887389871419, 0.19535743409209905, 0.14544946561512073, 0.17661593045290708, 0.11622345116152537, 0.10109240595166322, 0.16227402067072735, 0.08391260151693791, 0.09068683906008274, 0.18154559072707382, 0.10905539507113765, 0.12096066738941577, 0.11057908123054612, 0.11771217252314904, 0.11057908123054612, 0.1059119305364453, 0.1402836617057945, 0.1203914195353311, 0.07790843133362621, 0.17244796207910132, 0.09607093481047306, 0.1500960000105795, 0.10339492613738507, 0.14148556065792872, 0.16020385214358324, 0.12096066738941577, 0.09366107344463047]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                hello, call indian gentleman purporting bt. forceful said getting right speed router tried get go bt speed checker via google. smalt rat hung up. looking number called non existent local numbe blocked it. joined bt upgraded fttp last week potentially plausible. knew name. coincidence scammer hacked bt me? anybody got thought info? many thanks, john\n",
            "Embedding Values are : \n",
            "                [0.13299025468555076, 0.14165068337762418, 0.15502852430128686, 0.09036790181614854, 0.11784318798688993, 0.15067866982870579, 0.1752639384252471, 0.1752639384252471, 0.20474113082805756, 0.11012430491233309, 0.18614309308937393, 0.061592638301729896, 0.0841548803118246, 0.08683236121681578, 0.13806786294787984, 0.09488455661265491, 0.16754505535069028, 0.10031854525544444, 0.17112787578043462, 0.19386197616393072, 0.13299025468555076, 0.08327025193963658, 0.16754505535069028, 0.16754505535069028, 0.17112787578043462, 0.08999263280638578, 0.13920979259471933, 0.10973260019190888, 0.09746422107217292, 0.11837451815760767, 0.12180445329156207, 0.14165068337762418, 0.12369921419789393, 0.0925313021520222, 0.20474113082805756, 0.19386197616393072, 0.20474113082805756, 0.20474113082805756, 0.11133494470380441, 0.08889732575479721, 0.10290323383197289, 0.14894701761200665, 0.20474113082805756, 0.18465452177750327, 0.06890514083838883, 0.11175094213463942, 0.08283864000300187, 0.10260343968721172, 0.1194698252091962, 0.09602648625949438, 0.09721918469502075]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                delete profile &amp amp data bt\n",
            "Embedding Values are : \n",
            "                [0.5904738821991291, 0.13252875659619903, 0.3793054721616551, 0.48010177851104, 0.5093195108912624]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                place added fttp rollout. href=\"https: www.ispreview.co.uk index.php 170-new-additions-to-openreachs-uk-fttp-rollout-programme.html\" target=\"_self\" https: www.ispreview.co.uk index.php 170-new-additions-to-openreachs-uk-fttp-rollout-programme.html\n",
            "Embedding Values are : \n",
            "                [0.2754768971640489, 0.11271499721750579, 0.093652607963394, 0.2754768971640489, 0.20522718780899837, 0.22225652728083767, 0.0754640875353768, 0.2504534457995302, 0.12619238426559742, 0.2504534457995302, 0.26083911647718583, 0.09375421999640654, 0.2754768971640489, 0.26083911647718583, 0.08037265550955558, 0.18429503901992078, 0.3756801686992953, 0.0751798201707278, 0.16471647634827782, 0.3485443952386747, 0.1777130103583438]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                hi every please aware new scam rounds. scam involve text whatsapp message person claiming family member common aim encouraging recipient transfer mo\n",
            "Embedding Values are : \n",
            "                [0.2620984874015378, 0.1872567174732197, 0.22388044269991794, 0.22059317332624612, 0.2729670484891055, 0.14086981454933462, 0.1872567174732197, 0.08764692017384719, 0.2620984874015378, 0.20527479683238417, 0.12619287561957576, 0.25366817647501383, 0.09811340055683615, 0.19440623574481639, 0.10885910051178432, 0.23591154982010806, 0.2729670484891055, 0.3603042967243438, 0.1637694827570925, 0.22059317332624612, 0.2729670484891055]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                probably $64 million dollar question anybody aware plan bt release x box? thanks\n",
            "Embedding Values are : \n",
            "                [0.4181214823010579, 0.2715921427014873, 0.2715921427014873, 0.17035115205185236, 0.07914965121765931, 0.3959041180814215, 0.3679135494505337, 0.24631282204692465, 0.28196161308881307, 0.21397299655381985, 0.3801406473035217, 0.14071779084636227]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                span class=\"lia-inline-image-display-wrapper lia-image-align-cente image-alt=\"sft staying safe online_hero side-by-side full 1920x800 px.jpg\" style=\"width: 999px img src=\"https: community.bt.com t5 image serverpage image-id 74858i7b10da2a47760fa1 image-size large?v=v2&amp amp px=999\" role=\"button\" title=\"sft staying safe online_hero side-by-side full 1920x800 px.jpg\" alt=\"sft staying safe online_hero side-by-side full 1920x800 px.jpg\" span &amp n\n",
            "Embedding Values are : \n",
            "                [0.303745412921428, 0.10124847097380932, 0.0608519263805754, 0.06884194977233621, 0.05263814392409217, 0.10596560442658663, 0.1280904719404259, 0.01916615506047639, 0.04807677753796161, 0.287605552247969, 0.08285428826573109, 0.0455574852399964, 0.04269682398014196, 0.04606592284957462, 0.05134261831361146, 0.15311273890821736, 0.0463806079092812, 0.048694032928425446, 0.31282429608248036, 0.05263814392409217, 0.052982802213293316, 0.1898132335208526, 0.05679994000951279, 0.09318924439100351, 0.303745412921428, 0.21193120885317326, 0.05263814392409217, 0.2324230041237343, 0.052982802213293316, 0.303745412921428, 0.4202941064076871, 0.05118922240761554, 0.09406658697850726, 0.05263814392409217, 0.287605552247969, 0.05230221210550289, 0.05118922240761554, 0.045860204029761854, 0.05280935401681465, 0.05181374229214918, 0.052982802213293316]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                received e-mail end july asking accept new term service privacy policy e-mail account would suspended 21. thought looked little suspicious ignored account suspended. morning received second e-mail referring one july asking log e-mail account accept term service privacy policy, failure result account suspended 21. phish?\n",
            "Embedding Values are : \n",
            "                [0.23277774805636095, 0.2196239616185901, 0.2631325084278652, 0.1989760555341141, 0.08179451805672681, 0.13201529472338122, 0.13570007305742735, 0.24338268336228647, 0.10575636037735378, 0.0868736649039052, 0.103997831970813, 0.35194576408420997, 0.0872378247973137, 0.052485872719579066, 0.05493224555499604, 0.15421860863746742, 0.23601312669419422, 0.2804197545223666, 0.14362048475278508, 0.1402098772611833, 0.09695843968384839, 0.08651595065790764, 0.13312108646392024, 0.4626558259124023, 0.13570007305742735, 0.21151272075470756, 0.08417495175604686, 0.05370700210651346]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                phishing@bt.com working today. fowarded email rejected bt.\n",
            "Embedding Values are : \n",
            "                [0.21947077792481726, 0.2444597036878985, 0.22364783707348057, 0.5796958393116509, 0.3941530323302175, 0.44357755778091784, 0.2840379119485125, 0.2705757041586602]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                bt priority service elderly disabled. telling lie bt. hang head shame bt\n",
            "Embedding Values are : \n",
            "                [0.2334625086711644, 0.3192587729149726, 0.3364154144227299, 0.3364154144227299, 0.3300698730740566, 0.3519142379658798, 0.36173678134781234, 0.17743097797229465, 0.373758602857703, 0.2870504044778661]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                help, bt business customer mi sold cloud system restaurant instead normal bt business broadband package happened still ongoing, hundred email imp complaint resolve this, service bt decided close last complaint stating resolved december obviously stating \"resolving issue\" th generated bill since raised time much would product ordered first place. spent another min go everything told wont open new complaint go ombudsman raise complaint directly bt, howeve done automatically came case closed option relevant complaint select state can't help close case. could anyone help th &amp n\n",
            "Embedding Values are : \n",
            "                [0.060915987537374455, 0.0677501297850852, 0.05104043702501231, 0.10761527080665118, 0.0938293940147867, 0.053744161903788064, 0.10937818357134714, 0.18053896425586954, 0.08727423175282281, 0.060915987537374455, 0.18053896425586954, 0.19811798515137075, 0.11398483901209298, 0.10761527080665118, 0.4759107189874417, 0.06209952553747841, 0.07485821314259683, 0.10901816748526039, 0.09518214379748834, 0.08551198888563519, 0.07347244033863795, 0.0557299573320366, 0.08006604005976722, 0.0776966464246231, 0.11820904509807813, 0.12252668969032512, 0.08822095112566589, 0.14841865397060783, 0.07975313306564542, 0.11597936015708286, 0.13677657651667738, 0.08727423175282281, 0.056806860481375156, 0.06349302978615784, 0.14445221028354063, 0.10761527080665118, 0.08103704480109186, 0.04916203297376793, 0.09026948212793477, 0.0938293940147867, 0.11820904509807813, 0.11398483901209298, 0.07884429731988438, 0.07438492743789382, 0.09518214379748834, 0.06742373476607136, 0.08429024614575235, 0.09196587991261564, 0.12073685339938243, 0.11053341133121486, 0.12073685339938243, 0.09905899257568537, 0.09663905033337658, 0.11398483901209298, 0.14445221028354063, 0.10086325641936172, 0.062345378890896565, 0.06726262364778281, 0.12710642160482424, 0.10086325641936172, 0.09081822901735435, 0.19811798515137075, 0.056082161763685565, 0.08070781142205545, 0.2542128432096485, 0.0655753953678272, 0.054877090484268296, 0.06632373162346356, 0.12073685339938243, 0.05030583034389932]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                hi every wanted share change made today one community category one board sit categ\n",
            "Embedding Values are : \n",
            "                [0.24991267551801735, 0.4092048192161046, 0.4092048192161046, 0.1813740156560462, 0.1861795783223173, 0.1999567165043894, 0.12440983489438115, 0.24593854399990256, 0.2915152692670015, 0.2913759380391195, 0.37203394573380666, 0.20050114996068574, 0.26580029574910796]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                good morning every yet another scam make aware of. time email purport come\n",
            "Embedding Values are : \n",
            "                [0.22176194827087786, 0.3071254518301404, 0.2369506536232329, 0.1824171253134049, 0.23104487799685974, 0.23167395694797685, 0.23360044614047218, 0.26746634070118835, 0.3796274479359978, 0.44770157905788327, 0.2954730314110915, 0.17962549355747018, 0.26417545705681805]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                hi sorry, new forum contact moderator seem option pm anyone? edit posting envelope icon appeared allowing pm. many thanks.\n",
            "Embedding Values are : \n",
            "                [0.2776696876671741, 0.11461229148454731, 0.24820491940667322, 0.17978984617327085, 0.271116946509604, 0.28541993547960537, 0.19597598045335407, 0.09861772433827413, 0.2604339031423422, 0.1544120260391011, 0.271116946509604, 0.11039429874789668, 0.16703279757167655, 0.511910334438209, 0.2559551672191045, 0.16548685720326944, 0.20150436662134044, 0.10916603328196091]\n",
            ".......................................\n",
            "The Phrase is \n",
            "                hi every hope everyone keeping safe lookout scams. another example share a, particularly nasty\n",
            "Embedding Values are : \n",
            "                [0.18171975062197446, 0.18932651854586663, 0.23929969709473933, 0.2572143189606952, 0.11779589765819247, 0.25166968883256113, 0.3008913224063235, 0.36686284519870704, 0.331668068095244, 0.3110804432684786, 0.296473290991781, 0.36686284519870704, 0.2758856661650156]\n",
            ".......................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QdMCHxf0UPZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSPwFPvzU_Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Embedding"
      ],
      "metadata": {
        "id": "WCXbOnImU_b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "97ErvpckU_LC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = data['Text'].tolist()[:50]\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "len(sentence_embeddings) , len(sentence_embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocFvkpmQVf5Q",
        "outputId": "7728e967-820c-4009-99f8-6c746e1c0cf5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66LsrCeoVjC-",
        "outputId": "67aa3f8a-22be-4ccd-ec28-0151ebcc338b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.1173e-01, -5.5306e-02, -6.1294e-01, -3.3788e-01,  1.4534e-01,\n",
              "         5.4121e-01,  1.0451e+00,  2.7035e-01, -3.0665e-01, -1.0458e-02,\n",
              "        -4.0616e-01,  3.4595e-01, -4.0007e-01,  2.7574e-01, -1.9236e-01,\n",
              "         5.9931e-02,  5.5609e-01,  1.1027e-02, -2.5994e-01,  2.6097e-01,\n",
              "        -3.2247e-02, -1.6999e-01, -1.3412e-01, -1.7456e-01, -4.5100e-01,\n",
              "         2.3420e-01,  2.4647e-01, -5.3005e-02, -1.4202e-01, -4.8290e-01,\n",
              "         2.4680e-02,  4.9282e-01,  4.5610e-01, -2.4263e-02, -9.9776e-02,\n",
              "        -8.2648e-02, -2.7185e-01,  1.9150e-01,  2.4025e-01, -2.1919e-01,\n",
              "        -3.5536e-02, -2.0642e-01,  1.3488e-01,  6.1864e-01,  6.4730e-02,\n",
              "         4.0681e-01,  1.1163e-01, -3.9019e-01, -7.0170e-02, -1.1508e-01,\n",
              "        -1.8982e-01, -1.0747e+00, -2.8163e-01, -4.7188e-02, -4.3302e-01,\n",
              "        -3.6399e-01, -1.0482e-01, -7.8408e-02,  5.5549e-01, -3.6800e-01,\n",
              "        -1.4273e-01,  4.1017e-01,  1.4700e-01,  1.1036e-01,  4.8431e-01,\n",
              "         2.6857e-01, -3.5325e-01,  4.6689e-01, -5.8822e-01, -8.0611e-02,\n",
              "         1.1329e-01,  2.1967e-01, -2.4234e-01, -2.2580e-02,  9.1738e-02,\n",
              "        -2.5215e-01, -1.6272e-01,  9.5432e-02,  3.9541e-01, -5.4853e-01,\n",
              "        -3.4882e-01, -5.6078e-01, -1.5700e-01,  3.4700e-01,  9.1035e-02,\n",
              "        -1.9050e-01, -2.7763e-01,  1.6103e-01, -4.5442e-01, -3.4986e-01,\n",
              "         2.3413e-01,  5.7867e-01,  1.0733e+00,  1.6417e-01, -3.9967e-01,\n",
              "         4.3097e-01, -3.8603e-01, -2.6021e-01,  3.0981e-02,  1.0011e+00,\n",
              "        -2.2583e-02,  2.7048e-01, -5.6069e-03, -6.6991e-02, -4.2688e-01,\n",
              "        -2.9219e-01, -2.3390e-01,  7.2651e-02,  8.0717e-02, -1.9410e-01,\n",
              "        -6.6420e-01,  2.8428e-01, -1.1041e-01,  3.2622e-01,  5.6529e-01,\n",
              "        -5.2260e-01,  7.8858e-01,  5.8225e-02,  7.1855e-02, -2.7188e-01,\n",
              "         2.5834e-01, -1.9947e-01,  6.8515e-02,  1.2509e-01, -2.2805e-01,\n",
              "        -5.9777e-02, -4.8846e-01, -2.1118e-32, -1.0344e-01, -4.8865e-01,\n",
              "        -2.6502e-01,  2.3715e-01,  6.7374e-01, -3.8203e-01,  4.3038e-02,\n",
              "        -5.3083e-01,  2.1425e-01,  2.2014e-01, -7.7424e-02, -2.2305e-01,\n",
              "        -4.2374e-02, -1.7797e-01,  7.6167e-01, -4.7728e-01, -5.6757e-01,\n",
              "        -3.0231e-01, -3.9957e-01, -1.2259e-02, -1.9177e-01,  2.4584e-01,\n",
              "         4.8591e-01,  4.4881e-01,  3.5459e-01, -6.7144e-02, -4.3995e-02,\n",
              "        -6.8470e-01,  7.0994e-01, -7.2352e-02, -2.2755e-01, -1.9526e-01,\n",
              "        -6.3713e-01, -3.9564e-01,  4.3774e-02,  3.5857e-01,  4.8158e-01,\n",
              "        -3.3697e-01,  4.8607e-02, -1.2635e-01, -7.4299e-01, -2.1943e-01,\n",
              "         8.2673e-02, -3.2082e-01,  5.6111e-01,  7.4886e-02,  7.1568e-01,\n",
              "         4.0496e-01, -2.2588e-01, -3.8270e-01, -2.4853e-01, -1.0990e-01,\n",
              "         3.6552e-01, -3.7686e-01,  4.2533e-01, -2.8803e-01,  1.0724e-02,\n",
              "         4.1433e-02, -1.6876e-01,  3.1200e-01,  2.8869e-01,  4.2684e-01,\n",
              "         3.8358e-01, -1.1959e-01, -5.2164e-01,  3.4707e-01,  1.0945e-01,\n",
              "        -2.1317e-01,  4.0011e-01, -9.4005e-01, -1.1920e-01,  6.9777e-02,\n",
              "         1.6358e-01, -4.4398e-01, -6.0518e-01,  4.2129e-01, -4.9018e-01,\n",
              "        -3.5022e-01, -1.7561e-01, -3.2371e-01, -4.7460e-01, -3.0287e-01,\n",
              "        -8.8836e-02, -3.2617e-01,  2.1968e-01, -1.5638e-01,  5.8088e-01,\n",
              "        -3.2757e-01, -4.1710e-01, -3.4169e-02, -3.5782e-01, -5.6035e-02,\n",
              "         3.0097e-01,  3.5652e-01,  4.8988e-01,  1.1516e-32, -5.5778e-01,\n",
              "        -4.7844e-01, -2.7508e-01,  2.8345e-01,  1.0527e+00, -2.0408e-01,\n",
              "        -2.7656e-01, -5.4331e-01,  3.8518e-01,  2.3124e-01, -2.8908e-01,\n",
              "         1.7144e-01,  3.8947e-02,  2.8544e-01, -1.6344e-01,  4.9338e-02,\n",
              "         8.6663e-02,  1.6755e-01, -2.2278e-01, -4.0776e-01, -2.9501e-01,\n",
              "         3.7182e-01, -4.9700e-01, -9.3276e-02, -3.4624e-02,  6.0861e-01,\n",
              "         2.3435e-01, -2.8588e-01, -9.6337e-02,  3.4396e-01, -3.3984e-01,\n",
              "         5.8423e-02,  1.9624e-01,  6.7872e-02, -3.9043e-01,  6.9202e-01,\n",
              "         1.7172e-01, -2.5075e-01,  3.0859e-01,  3.8462e-01,  9.4212e-01,\n",
              "        -2.6133e-01, -3.6344e-01,  3.6110e-01, -5.9049e-01, -5.3765e-02,\n",
              "        -3.9928e-01,  5.6842e-01,  3.1476e-01,  2.0457e-01, -3.9293e-01,\n",
              "        -2.0296e-02,  4.4357e-01, -3.6214e-01, -7.1323e-02,  7.6596e-01,\n",
              "         2.7363e-01, -1.0481e-01,  4.2253e-01,  1.8341e-01,  1.4241e-01,\n",
              "         4.6254e-01,  2.2510e-01,  3.1005e-02,  7.2963e-01, -2.5118e-01,\n",
              "        -5.5398e-01,  2.7220e-02, -3.8873e-04, -1.8233e-01, -8.5603e-02,\n",
              "         4.4974e-01, -7.5660e-01,  4.4113e-01, -3.8942e-01,  7.2506e-01,\n",
              "         1.6345e-01,  1.9595e-01,  3.5683e-02,  1.5360e-01, -3.6920e-01,\n",
              "        -6.2832e-02, -2.6621e-01,  2.4705e-01,  1.7567e-01,  3.0955e-01,\n",
              "         4.3826e-03,  4.6518e-01,  4.1216e-01, -8.5257e-01, -2.8330e-01,\n",
              "        -4.0502e-01,  3.7814e-01, -4.7450e-01, -2.0561e-01, -9.1418e-08,\n",
              "        -5.3228e-02,  1.0191e-01,  4.8929e-01, -1.0450e-01,  1.5765e-02,\n",
              "         3.2415e-01,  2.0629e-02, -3.6548e-01, -3.8644e-01,  6.8579e-01,\n",
              "        -1.7570e-01,  1.7475e-01, -2.2051e-01,  6.9204e-01,  2.9366e-01,\n",
              "        -9.9906e-02,  1.0741e-01,  8.1050e-02, -3.5608e-01, -4.0143e-01,\n",
              "         7.4744e-01,  2.1975e-01,  6.3594e-02,  6.6356e-01, -4.2176e-01,\n",
              "        -1.6657e-01,  7.8676e-02,  2.7170e-01, -3.1098e-01,  2.3313e-01,\n",
              "         1.1127e-01,  4.3060e-01,  2.7987e-01, -1.1291e-01,  6.9654e-01,\n",
              "         2.7460e-01,  8.0226e-02, -1.0105e-01, -2.9269e-01, -4.5885e-01,\n",
              "        -1.0515e+00, -6.8973e-02, -2.6379e-03, -2.5015e-02,  6.7399e-01,\n",
              "         6.6029e-02, -6.9986e-01,  2.7148e-01, -5.0699e-01, -9.8657e-03,\n",
              "        -6.2990e-01,  3.8652e-02, -1.1003e-01,  2.4564e-01,  5.7829e-01,\n",
              "         7.7761e-01,  3.4963e-02,  3.9905e-01,  5.9204e-02, -6.2096e-02,\n",
              "         5.7214e-01,  4.8751e-01, -3.2890e-01,  1.2209e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLEELyGwWbdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}